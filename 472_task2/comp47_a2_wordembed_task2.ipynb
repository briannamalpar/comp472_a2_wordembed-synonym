{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc1315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (23.3.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (69.0.2)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.26.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.11.3)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fasttext) (69.0.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fasttext) (1.26.1)\n",
      "Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-macosx_10_15_universal2.whl size=352899 sha256=a6d04ab93f0eaf67a3b9290f207bf3f0f831ec575fff7f1168716b944c45e18e\n",
      "  Stored in directory: /Users/briannam/Library/Caches/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools\n",
    "!pip install --no-cache-dir gensim\n",
    "!pip install numpy scipy\n",
    "\n",
    "!pip install nltk\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139c9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "\n",
    "gigaword500_model = KeyedVectors.load_word2vec_format('/Users/briannam/Downloads/11/gigaword500.bin', binary=True)\n",
    "#vocab size:261794\n",
    "#vector size:300\n",
    "\n",
    "\n",
    "engCoNLL17_model = KeyedVectors.load_word2vec_format('/Users/briannam/Downloads/40/model.bin', binary=True)\n",
    "#vocab size:4027169\n",
    "#vector size:100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c057fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "#helper functions\n",
    "def read_synonym_data(file_path):\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "\n",
    "def find_best_synonym(word, answer_options, model, topn=1):\n",
    "    try:\n",
    "        # calculate the cosine similarity between the word and each answer option\n",
    "        similarities = [(option, model.similarity(word, option.lower())) for option in answer_options]\n",
    "\n",
    "        sorted_options = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # return highest similarity\n",
    "        best_guess = sorted_options[0][0]\n",
    "        return best_guess\n",
    "\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "def generate_label(question_word, correct_answer, model_guess, model):\n",
    "    if (\n",
    "        correct_answer not in [question_word] + [model_guess]\n",
    "        and (model_guess not in model.key_to_index or question_word not in model.key_to_index)\n",
    "    ):\n",
    "        return \"guess\"\n",
    "    elif model_guess == correct_answer:\n",
    "        return \"correct\"\n",
    "    else:\n",
    "        return \"wrong\"\n",
    "\n",
    "\n",
    "def process_synonym_test_data(data, model):\n",
    "    correct_count = 0\n",
    "    valid_count = 0\n",
    "    results = []\n",
    "\n",
    "    for entry in data:\n",
    "        question_word = entry['question']\n",
    "        correct_answer = entry['answer']\n",
    "        guess_options = [entry[str(i)] for i in range(4)]  # Options are in columns 0 to 3\n",
    "\n",
    "        model_guess = find_best_synonym(question_word, guess_options, model)\n",
    "        \n",
    "        # if correct answer not in model, randomly select one as system guess\n",
    "        if correct_answer not in [question_word] + [model_guess]:\n",
    "            model_guess = random.choice(guess_options)\n",
    "\n",
    "        # generate label\n",
    "        label = generate_label(question_word, correct_answer, model_guess, model)\n",
    "\n",
    "        if label == 'correct':\n",
    "            correct_count += 1\n",
    "        if label != 'guess':\n",
    "            valid_count += 1\n",
    "\n",
    "        results.append({\n",
    "            'question_word': question_word,\n",
    "            'correct_answer': correct_answer,\n",
    "            'model_guess': model_guess,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "    return results, correct_count, valid_count\n",
    "    \n",
    "def write_to_csv(results, file_name):\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        csv_info = ['question_word', 'correct_answer', 'model_guess', 'label']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_info)\n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            writer.writerow(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b23b6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_test_file = '/Users/briannam/Downloads/A2-DataSet/synonym.csv'\n",
    "#home computer: 'Users/briannam/Downloads/A2-Dataset/synonym.csv'\n",
    "#uni computer: 'C:/Users/b_malpar/Downloads/A2-DataSet/synonym.csv'\n",
    "synonym_test_data = read_synonym_data(synonym_test_file)\n",
    "\n",
    "results, correct_count, valid_count = process_synonym_test_data(synonym_test_data, gigaword500_model)\n",
    "\n",
    "accuracy = correct_count / valid_count if valid_count > 0 else 0\n",
    "    \n",
    "# write results to csv file\n",
    "write_to_csv(results, 'gigaword500_model-details.csv')\n",
    "\n",
    "#write analysis to csv file\n",
    "with open('analysis_gigaword.csv', 'w', newline='') as csvfile:\n",
    "    csv_info = ['model_name', 'vocab_size', 'C', 'V', 'accuracy']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_info)\n",
    "    writer.writeheader()\n",
    "\n",
    "    model_name = 'gigaword500-5th-edition'\n",
    "    vocabulary_size = 261794\n",
    "\n",
    "    writer.writerow({\n",
    "        'model_name': model_name,\n",
    "        'vocab_size': vocabulary_size,\n",
    "        'C': correct_count,\n",
    "        'V': valid_count,\n",
    "        'accuracy': accuracy\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39065da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, correct_count, valid_count = process_synonym_test_data(synonym_test_data, engCoNLL17_model)\n",
    "\n",
    "accuracy = correct_count / valid_count if valid_count > 0 else 0\n",
    "    \n",
    "# write results to csv file\n",
    "write_to_csv(results, 'engCoNLL17_model-details.csv')\n",
    "\n",
    "#write analysis to csv file\n",
    "with open('analysis_engCoNLL17.csv', 'w', newline='') as csvfile:\n",
    "    csv_info = ['model_name', 'vocab_size', 'C', 'V', 'accuracy']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_info)\n",
    "    writer.writeheader()\n",
    "\n",
    "    model_name = 'English-CoNLL17'\n",
    "    vocabulary_size = 4027169\n",
    "\n",
    "    writer.writerow({\n",
    "        'model_name': model_name,\n",
    "        'vocab_size': vocabulary_size,\n",
    "        'C': correct_count,\n",
    "        'V': valid_count,\n",
    "        'accuracy': accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a4d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
